{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Índice\n",
    "\n",
    "1. [Importando bibliotecas](#importando-bibliotecas)\n",
    "2. [Treinamento do modelo](#treinamento-do-modelo)\n",
    "3. [Impacto do tamanho da vizinhança](#impacto-do-tamanho-da-vizinhança)\n",
    "4. [Personalizando a medida de distância](#personalizando-a-medida-de-distância)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas de manipualção e visualização de dados\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "# Classes do modelo de aprendizado\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Funções de avaliação dos modelos\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise do conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregando o csv\n",
    "dataset = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantas classes existem nesse dataset?\n",
      "3\n",
      "\n",
      "Quantas instâncias existem no dataset?\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "# carregando o dataset\n",
    "dataset = load_iris(as_frame=True) \n",
    "\n",
    "print(\"Quantas classes existem nesse dataset?\\n%d\" %(len(dataset[\"target\"].unique())))\n",
    "print(\"\\nQuantas instâncias existem no dataset?\\n%d\" %(len(dataset[\"data\"])))\n",
    "print(\"\\nQuantas features existem no dataset?\\n%d\" %(len(dataset[])))\n",
    "# print(\"\\nQue features são essas?\\n%s\" %  list((X.columns)))\n",
    "# print(\"\\nQual o numero de instâncias por classe?\")\n",
    "# frequency = np.unique(y.values, return_counts=True)[1]\n",
    "# for c in range(3):\n",
    "#     print(\"Classe %d: %d\" %(c, frequency[c]))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando o dataset\n",
    "X, y = load_wine(return_X_y=True, as_frame=True)\n",
    "\n",
    "# vamos escolher apenas classes do dataset\n",
    "class_a = 0\n",
    "class_b = 1\n",
    "class_0_instances = (y == class_a)\n",
    "class_1_instances = (y == class_b)\n",
    "\n",
    "filtered_y = y[class_0_instances | class_1_instances]\n",
    "filtered_X = X[class_0_instances | class_1_instances]\n",
    "\n",
    "# cores e simbolos para as classses\n",
    "colors = {0: \"steelblue\", 1: \"darkorange\", 2: \"mediumseagreen\"}\n",
    "markers = {0: \"s\", 1: \"^\", 2:\"o\"}\n",
    "\n",
    "# vamos observar as duas features\n",
    "feature_0 = \"alcohol\"\n",
    "feature_1 = \"color_intensity\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividindo o dataset em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(filtered_X[[feature_0, feature_1]], filtered_y, test_size=0.3, random_state=199)\n",
    "\n",
    "# vamos criar um classificador kNN com k=11\n",
    "model = KNeighborsClassifier(n_neighbors=11)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# e ver a sua performance no dataset de teste\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos fazer uma pequena modificação na nossa função de gerar a região de decisão, agora vamos incluir o tamanho da vizinhança para o kNN\n",
    "def show_decision_region(x, y, clf, f0, f1):\n",
    "    plot_decision_regions(x, y, clf=clf)\n",
    "    plt.xlabel(f0)\n",
    "    plt.ylabel(f1)\n",
    "    if clf.__class__.__name__ == \"KNeighborsClassifier\":\n",
    "        plt.title(clf.__class__.__name__ + \" k = \" + str(clf.n_neighbors))\n",
    "    else:\n",
    "        plt.title(clf.__class__.__name__)\n",
    "    plt.show()\n",
    "\n",
    "show_decision_region(\n",
    "    np.array(\n",
    "        [\n",
    "            X_test[feature_0].values, \n",
    "            X_test[feature_1].values,\n",
    "        ]\n",
    "    ).T, \n",
    "    y_test.values, \n",
    "    model, \n",
    "    feature_0, \n",
    "    feature_1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impacto do tamanho da vizinhança\n",
    "\n",
    "Vamos voltar um pouco e rever como o dataset de treino se comporta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    X_train[feature_0][class_0_instances],\n",
    "    X_train[feature_1][class_0_instances], \n",
    "    c=colors[class_a], \n",
    "    marker=markers[class_a]\n",
    ")\n",
    "plt.scatter(\n",
    "    X_train[feature_0][class_1_instances], \n",
    "    X_train[feature_1][class_1_instances], \n",
    "    c=colors[class_b], \n",
    "    marker=markers[class_b]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que a classe triangulo laranja tem alguns exemplares bem próximos dos quadrados azuis. O que acontece se mudarmos o tamanho da vizinhança no nosso classificador?\n",
    "\n",
    "Agora vamos observar a região de decisão, reduzindo o tamanho da vizinhança.\n",
    "\n",
    "A medida em que a quantidade de vizinhos reduz, a região de decisão fica menos suave. Isso porque quanto menos vizinhos para decidir se uma instancia é de uma classe ou não, maior a sensibilidade do algoritmo.\n",
    "\n",
    "Decidir o valor ideal para esse hiperparâmetro é depende de problema para problema. Para alguns datasets, um valor menor de vizinhos pode ser beneficial para diferenciar padrões com baixa ocorrência ou que estão próximos de outras classe com maior frequência. Entretanto, quanto menor a quantidade de vizinhos, maior é a chance do algoritmo ser afetado por ruído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [11, 9, 7, 5, 3, 1]:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # e ver a sua performance no dataset de teste\n",
    "    show_decision_region(\n",
    "        np.stack(\n",
    "            [\n",
    "                X_test[feature_0].values, \n",
    "                X_test[feature_1].values,\n",
    "            ],\n",
    "            axis=1\n",
    "        ), \n",
    "        y_test.values, \n",
    "        model, \n",
    "        feature_0, \n",
    "        feature_1\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalizando a medida de distância"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos mudar a métrica utilizada para calcular a distância entre as amostras.\n",
    "\n",
    "O hiperparâmetro _metric_ pode assumir dois tipos diferentes, uma _string_ ou uma função. Caso o valor seja uma _string_, as possíveis funções de distâncias estão presentes [aqui](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html#sklearn.neighbors.DistanceMetric). Entretanto, você tamém pode criar uma função que calcula a distância entre métricas.\n",
    "\n",
    "Vamos definir duas distâncias diferentes, a distância Euclidiana e a distância Manhattan:\n",
    "\n",
    "- Manhattan: $D_M(x, y) = |x_1-x_2| + |y_1-y_2|$\n",
    "- Euclidiana: $D(x, y) = \\sqrt{(x_1-x_2)^2 + (y_1-y_2)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos implementar a distância manhattan, com pesos diferentes para cada uma das features\n",
    "def knn_custom_distance(x, y, weights=np.array([2, 1])):\n",
    "    return (abs(x - y)*weights).sum()\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=11, metric=knn_custom_distance)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# e ver a sua performance no dataset de test\n",
    "print(classification_report(y_test, model.predict(X_test)))\n",
    "\n",
    "show_decision_region(\n",
    "    np.array(\n",
    "        [\n",
    "            X_test[feature_0].values, \n",
    "            X_test[feature_1].values,\n",
    "        ]\n",
    "    ).T, \n",
    "    y_test.values, \n",
    "    model, \n",
    "    feature_0, \n",
    "    feature_1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O comportamento padrão do algoritmo atribui pesos iguais para as distâncias entre a instância de teste e as de treino. Entretanto, podemos atribuir pesos diferentes em função das distâncias. Isso pode ser feito mudando o hiperparâmetro _weights_ de três formas diferentes: \n",
    "\n",
    "- _\"uniform\"_ atribui o rótulo da classe majoritária dos k vizinhos da instancia de teste.\n",
    "- _\"distance\"_ utiliza como peso o inverso da distância ($1/d$), dando peso menor instâncias mais longe da instancia de teste.\n",
    "- E uma _função customizada_, onde você pode definir a função para atribuir pesos diferentes para um vetor de distâncias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos criar um classificador kNN com k=11\n",
    "model = KNeighborsClassifier(n_neighbors=11, weights=\"distance\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# e ver a sua performance no dataset de teste\n",
    "print(classification_report(y_test, model.predict(X_test)))\n",
    "\n",
    "show_decision_region(\n",
    "    np.array(\n",
    "        [\n",
    "            X_test[feature_0].values, \n",
    "            X_test[feature_1].values,\n",
    "        ]\n",
    "    ).T, \n",
    "    y_test.values, \n",
    "    model, \n",
    "    feature_0, \n",
    "    feature_1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
